{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a166af57-547d-44da-bdc1-0a3a6f87c3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Frame 0/10000 | Active Users: 18 | 0.0%\n",
      "Current number of users : 18\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 18, 3)]           0         \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 18, 128)           512       \n",
      "                                                                 \n",
      " tf.__operators__.add_32 (T  (None, 18, 128)           0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_32 (Tr  (None, 64)                808000    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " flatten_65 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 18)                1170      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813842 (3.10 MB)\n",
      "Trainable params: 813842 (3.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Current number of users : 6\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 6, 3)]            0         \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 6, 128)            512       \n",
      "                                                                 \n",
      " tf.__operators__.add_33 (T  (None, 6, 128)            0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_33 (Tr  (None, 64)                709696    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " flatten_67 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 714758 (2.73 MB)\n",
      "Trainable params: 714758 (2.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Current number of users : 23\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 23, 3)]           0         \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 23, 128)           512       \n",
      "                                                                 \n",
      " tf.__operators__.add_34 (T  (None, 23, 128)           0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_34 (Tr  (None, 64)                848960    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " flatten_69 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 23)                1495      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 855127 (3.26 MB)\n",
      "Trainable params: 855127 (3.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Time Frame 1000/10000 | Active Users: 23 | 10.0%\n",
      "Current number of users : 17\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 17, 3)]           0         \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 17, 128)           512       \n",
      "                                                                 \n",
      " tf.__operators__.add_35 (T  (None, 17, 128)           0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_35 (Tr  (None, 64)                799808    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " flatten_71 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 17)                1105      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805585 (3.07 MB)\n",
      "Trainable params: 805585 (3.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Time Frame 2000/10000 | Active Users: 17 | 20.0%\n",
      "Current number of users : 21\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 21, 3)]           0         \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 21, 128)           512       \n",
      "                                                                 \n",
      " tf.__operators__.add_36 (T  (None, 21, 128)           0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_36 (Tr  (None, 64)                832576    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " flatten_73 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 838613 (3.20 MB)\n",
      "Trainable params: 838613 (3.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Current number of users : 18\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_38 (InputLayer)       [(None, 18, 3)]           0         \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 18, 128)           512       \n",
      "                                                                 \n",
      " tf.__operators__.add_37 (T  (None, 18, 128)           0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_37 (Tr  (None, 64)                808000    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " flatten_75 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 18)                1170      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813842 (3.10 MB)\n",
      "Trainable params: 813842 (3.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Time Frame 3000/10000 | Active Users: 18 | 30.0%\n",
      "Current number of users : 17\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 17, 3)]           0         \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 17, 128)           512       \n",
      "                                                                 \n",
      " tf.__operators__.add_38 (T  (None, 17, 128)           0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_38 (Tr  (None, 64)                799808    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " flatten_77 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 17)                1105      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805585 (3.07 MB)\n",
      "Trainable params: 805585 (3.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Current number of users : 21\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 21, 3)]           0         \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 21, 128)           512       \n",
      "                                                                 \n",
      " tf.__operators__.add_39 (T  (None, 21, 128)           0         \n",
      " FOpLambda)                                                      \n",
      "                                                                 \n",
      " transformer_encoder_39 (Tr  (None, 64)                832576    \n",
      " ansformerEncoder)                                               \n",
      "                                                                 \n",
      " flatten_79 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 838613 (3.20 MB)\n",
      "Trainable params: 838613 (3.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_39/transformer_encoder_39/transformer_encoder_layer_78/multi_head_attention_78/einsum_1/Einsum' defined at (most recent call last):\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\runpy.py\", line 198, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\runpy.py\", line 88, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Ananya\\AppData\\Local\\Temp\\ipykernel_15264\\724719542.py\", line 171, in <module>\n      mem.encode(nn_input, m_list[best_idx])\n    File \"<string>\", line 101, in encode\n    File \"<string>\", line 115, in learn\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"<string>\", line 47, in call\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"<string>\", line 27, in call\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\layers\\attention\\multi_head_attention.py\", line 598, in call\n      attention_output, attention_scores = self._compute_attention(\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\layers\\attention\\multi_head_attention.py\", line 540, in _compute_attention\n      attention_output = tf.einsum(\nNode: 'model_39/transformer_encoder_39/transformer_encoder_layer_78/multi_head_attention_78/einsum_1/Einsum'\nOOM when allocating tensor with shape[32,21,4,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node model_39/transformer_encoder_39/transformer_encoder_layer_78/multi_head_attention_78/einsum_1/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1149614]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 171\u001b[0m\n\u001b[0;32m    169\u001b[0m best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(v_list)\n\u001b[0;32m    170\u001b[0m k_idx_his\u001b[38;5;241m.\u001b[39mappend(best_idx)\n\u001b[1;32m--> 171\u001b[0m \u001b[43mmem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m mode_his\u001b[38;5;241m.\u001b[39mappend(m_list[best_idx])\n\u001b[0;32m    174\u001b[0m Obj[i]                   \u001b[38;5;241m=\u001b[39m r_list[best_idx][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m<string>:101\u001b[0m, in \u001b[0;36mencode\u001b[1;34m(self, h, m)\u001b[0m\n",
      "File \u001b[1;32m<string>:115\u001b[0m, in \u001b[0;36mlearn\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32m~\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_39/transformer_encoder_39/transformer_encoder_layer_78/multi_head_attention_78/einsum_1/Einsum' defined at (most recent call last):\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\runpy.py\", line 198, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\runpy.py\", line 88, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\Ananya\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Ananya\\AppData\\Local\\Temp\\ipykernel_15264\\724719542.py\", line 171, in <module>\n      mem.encode(nn_input, m_list[best_idx])\n    File \"<string>\", line 101, in encode\n    File \"<string>\", line 115, in learn\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"<string>\", line 47, in call\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"<string>\", line 27, in call\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\layers\\attention\\multi_head_attention.py\", line 598, in call\n      attention_output, attention_scores = self._compute_attention(\n    File \"C:\\Users\\Ananya\\mlenv\\Lib\\site-packages\\keras\\src\\layers\\attention\\multi_head_attention.py\", line 540, in _compute_attention\n      attention_output = tf.einsum(\nNode: 'model_39/transformer_encoder_39/transformer_encoder_layer_78/multi_head_attention_78/einsum_1/Einsum'\nOOM when allocating tensor with shape[32,21,4,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node model_39/transformer_encoder_39/transformer_encoder_layer_78/multi_head_attention_78/einsum_1/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1149614]"
     ]
    }
   ],
   "source": [
    "# LyDROOwithTF2Transformer.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Dynamic user simulation using a transformer-based MemoryDNN.\n",
    "Runs simulation for varying user counts per frame and saves results,\n",
    "re‑using the same saved user sequence.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import import_ipynb\n",
    "from MemoryTF2Transformer import MemoryDNN\n",
    "from ResourceAllocation import Algo1_NUM\n",
    "\n",
    "USERS_FILENAME = \"user_count_list.npy\"\n",
    "\n",
    "def generate_user_count_sequence(n, min_users, max_users, max_changes):\n",
    "    change_points = sorted(random.sample(range(1, n), min(max_changes, n - 1)))\n",
    "    change_points = [0] + change_points + [n]\n",
    "\n",
    "    user_counts = []\n",
    "    for i in range(len(change_points) - 1):\n",
    "        user_value = random.randint(min_users, max_users)\n",
    "        user_counts.extend([user_value] * (change_points[i + 1] - change_points[i]))\n",
    "    return np.array(user_counts)\n",
    "\n",
    "def load_or_create_user_counts(n, min_users, max_users, max_changes, filename=USERS_FILENAME):\n",
    "    if os.path.exists(filename):\n",
    "        user_counts = np.load(filename)\n",
    "        if len(user_counts) != n:\n",
    "            print(f\"[INFO] Regenerating user count list: existing length {len(user_counts)} != {n}\")\n",
    "            user_counts = generate_user_count_sequence(n, min_users, max_users, max_changes)\n",
    "            np.save(filename, user_counts)\n",
    "    else:\n",
    "        user_counts = generate_user_count_sequence(n, min_users, max_users, max_changes)\n",
    "        np.save(filename, user_counts)\n",
    "    return user_counts\n",
    "\n",
    "\n",
    "def plot_rate(rate_his, rolling_intv=50, ylabel='Normalized Computation Rate'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import matplotlib as mpl\n",
    "\n",
    "    rate_array = np.asarray(rate_his)\n",
    "    df = pd.DataFrame(rate_array)\n",
    "    mpl.style.use('eaborn-v0_8')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    plt.plot(\n",
    "        np.arange(len(rate_array)) + 1,\n",
    "        np.hstack(df.rolling(rolling_intv, min_periods=1).mean().values),\n",
    "        linewidth=2,\n",
    "        label='Rolling Mean'\n",
    "    )\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('Time Frames')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def racian_mec(h, factor):\n",
    "    n = len(h)\n",
    "    beta = np.sqrt(h * factor)\n",
    "    sigma = np.sqrt(h * (1 - factor) / 2)\n",
    "    x = sigma * np.random.randn(n) + beta\n",
    "    y = sigma * np.random.randn(n)\n",
    "    return np.power(x, 2) + np.power(y, 2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    n = 10000\n",
    "    min_users = 5\n",
    "    N = 30             # maximum user count\n",
    "    max_changes = 20\n",
    "    lambda_param = 0.05\n",
    "    nu = 1000\n",
    "    Delta = 10\n",
    "    V = 1.0\n",
    "    Memory_capacity = 1000\n",
    "    decoder_mode = 'OP'\n",
    "    CHFACT = 1.0\n",
    "\n",
    "    # load or create the SAME user sequence\n",
    "    user_count_list = load_or_create_user_counts(n, min_users, N, max_changes)\n",
    "\n",
    "    # Initialize arrays for the max user capacity\n",
    "    channel    = np.zeros((n, N))\n",
    "    dataA      = np.zeros((n, N))\n",
    "    Q          = np.zeros((n, N))\n",
    "    Y          = np.zeros((n, N))\n",
    "    Obj        = np.zeros(n)\n",
    "    energy_arr = np.zeros((n, N))\n",
    "    rate_arr   = np.zeros((n, N))\n",
    "\n",
    "    # Fixed parameters based on N\n",
    "    energy_thresh   = np.ones(N) * 0.08\n",
    "    w               = np.array([1.5 if i % 2 == 0 else 1 for i in range(N)])\n",
    "    arrival_lambda  = lambda_param * np.ones(N)\n",
    "\n",
    "    dist_v = np.linspace(start=120, stop=255, num=N)\n",
    "    Ad, fc = 3, 915e6\n",
    "    loss_exponent = 3\n",
    "    light = 3e8\n",
    "    h0 = np.array([Ad * (light / (4 * math.pi * fc * dist_v[j])) ** loss_exponent for j in range(N)])\n",
    "\n",
    "    mem = None\n",
    "    mode_his, k_idx_his = [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(n):\n",
    "        current_N = user_count_list[i]\n",
    "        if i % (n // 10) == 0:\n",
    "            print(f\"Time Frame {i}/{n} | Active Users: {current_N} | {100 * i / n:.1f}%\")\n",
    "\n",
    "        # same K‑update logic\n",
    "        K = current_N\n",
    "        if i > 0 and i % Delta == 0:\n",
    "            if Delta > 1:\n",
    "                recent_k = np.array(k_idx_his[-Delta:-1]) % current_N\n",
    "                max_k = max(recent_k) + 1\n",
    "            else:\n",
    "                max_k = k_idx_his[-1] + 1\n",
    "            K = min(max_k + 1, current_N)\n",
    "\n",
    "        h_tmp = racian_mec(h0[:current_N], 0.3)\n",
    "        h_curr = h_tmp * CHFACT\n",
    "        channel[i, :current_N] = h_curr\n",
    "        dataA[i, :current_N]  = np.random.exponential(arrival_lambda[:current_N])\n",
    "\n",
    "        if i > 0:\n",
    "            Q[i, :current_N] = Q[i-1, :current_N] + dataA[i-1, :current_N] - rate_arr[i-1, :current_N]\n",
    "            Q[i, :current_N][Q[i, :current_N] < 0] = 0\n",
    "            Y[i, :current_N] = np.maximum(\n",
    "                Y[i-1, :current_N] + (energy_arr[i-1, :current_N] - energy_thresh[:current_N]) * nu,\n",
    "                0\n",
    "            )\n",
    "\n",
    "        nn_input = np.vstack((\n",
    "            h_curr,\n",
    "            Q[i, :current_N] / 10000,\n",
    "            Y[i, :current_N] / 10000\n",
    "        )).transpose().flatten()\n",
    "\n",
    "        if mem is None or current_N * 3 != mem.net[0]:\n",
    "            print(f\"Current number of users : {current_N}\")\n",
    "            mem = MemoryDNN(\n",
    "                net=[current_N * 3, 256, 128, current_N],\n",
    "                learning_rate=0.01,\n",
    "                training_interval=20,\n",
    "                batch_size=128,\n",
    "                memory_size=Memory_capacity\n",
    "            )\n",
    "\n",
    "        m_pred, m_list = mem.decode(nn_input, K, decoder_mode)\n",
    "\n",
    "        r_list, v_list = [], []\n",
    "        for m in m_list:\n",
    "            res = Algo1_NUM(m, h_curr, w[:current_N],\n",
    "                            Q[i, :current_N], Y[i, :current_N],\n",
    "                            current_N, V)\n",
    "            r_list.append(res)\n",
    "            v_list.append(res[0])\n",
    "\n",
    "        best_idx = np.argmax(v_list)\n",
    "        k_idx_his.append(best_idx)\n",
    "        mem.encode(nn_input, m_list[best_idx])\n",
    "        mode_his.append(m_list[best_idx])\n",
    "\n",
    "        Obj[i]                   = r_list[best_idx][0]\n",
    "        rate_arr[i, :current_N]  = r_list[best_idx][1]\n",
    "        energy_arr[i, :current_N]= r_list[best_idx][2]\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    mem.plot_cost()\n",
    "    plot_rate(np.sum(Q, axis=1) / user_count_list, rolling_intv=50, ylabel='Average Data Queue')\n",
    "    plot_rate(np.sum(energy_arr, axis=1) / user_count_list, rolling_intv=50, ylabel='Average Energy Consumption')\n",
    "\n",
    "    print(f'Average time per frame: {total_time/n:.4f} seconds')\n",
    "\n",
    "    filename = \"./result_transformer_dynamic_users.mat\"\n",
    "    sio.savemat(filename, {\n",
    "        'input_h': channel / CHFACT,\n",
    "        'data_arrival': dataA,\n",
    "        'data_queue': Q,\n",
    "        'energy_queue': Y,\n",
    "        'off_mode': mode_his,\n",
    "        'rate': rate_arr,\n",
    "        'energy_consumption': energy_arr,\n",
    "        'data_rate': rate_arr,\n",
    "        'objective': Obj,\n",
    "        'user_count_list': user_count_list\n",
    "    })\n",
    "    print(f\"Results saved in {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cddbbfa-2ab6-40f6-bcf4-e8b7907ea152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
